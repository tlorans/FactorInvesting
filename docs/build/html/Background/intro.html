

<!DOCTYPE html>


<html >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Background &#8212; Factor Models with Machine Learning 0.1 documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=12da95d707ffb74b382d" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=12da95d707ffb74b382d" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=12da95d707ffb74b382d" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=12da95d707ffb74b382d" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=12da95d707ffb74b382d" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=12da95d707ffb74b382d" />

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'Background/intro';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Testing Asset Pricing Models" href="../TestFramework/intro.html" />
    <link rel="prev" title="Factor Models with Machine Learning" href="../index.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="None"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
    <p class="title logo__title">Factor Models with Machine Learning 0.1 documentation</p>
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Background</a></li>
<li class="toctree-l1"><a class="reference internal" href="../TestFramework/intro.html">Testing Asset Pricing Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../LinearRegressions/intro.html">Linear Regression: Static Models with Observable Factors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../PCA/intro.html">Principal Component Analysis: Static Models with Latent Factors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../InstrumentedPCA/intro.html">Instrumented PCA: Conditional Models with Latent Factors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Autoencoders/intro.html">Autoencoders: Conditional Non-Linear Models with Latent Factors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../StateVariablesNLP/intro.html">Latent Dirichlet Allocation: State Variables with Natural Language Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../IPCANLP/intro.html">IPCA with Natural Language Processing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../references.html">References</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/Background/intro.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Background</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#linear-algebra">Linear Algebra</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#vectors">Vectors</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#norms">Norms</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#vector-norm">Vector Norm</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#vector-l-1-norm">Vector <span class="math notranslate nohighlight">\(L^1\)</span> Norm</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#vector-l-2-norm">Vector <span class="math notranslate nohighlight">\(L^2\)</span> Norm</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#vector-max-norm">Vector Max Norm</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#types-of-matrices">Types of Matrices</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#orthogonal-matrix">Orthogonal Matrix</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#matrix-operations">Matrix Operations</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#trace">Trace</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#determinant">Determinant</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sparse-matrices">Sparse Matrices</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#statistics">Statistics</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#probability">Probability</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#distributions">Distributions</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#maximum-likelihood">Maximum Likelihood</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesian-probability">Bayesian Probability</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#information-theory">Information Theory</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#classification">Classification</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#calculus">Calculus</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#limits-and-differential-calculus">Limits and Differential Calculus</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#multivariate-calculus">Multivariate Calculus</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mathematical-programming">Mathematical Programming</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#approximation">Approximation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#gradient-descent">Gradient Descent</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#optimization">Optimization</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="background">
<h1>Background<a class="headerlink" href="#background" title="Permalink to this headline">#</a></h1>
<section id="linear-algebra">
<h2>Linear Algebra<a class="headerlink" href="#linear-algebra" title="Permalink to this headline">#</a></h2>
<p>Linear algebra is the the maths of data, with vectors and matrices of numbers. Classical methods such as linear regression are linear algebra methods, and other methods such as PCA were born from the marriage of linear algebra and stats.</p>
<p>To understand machine learning, you need to be able to read and understand linear algebra.</p>
<p>Linear equation is a serie of terms and operations where some terms are unknown, for example:</p>
<div class="amsmath math notranslate nohighlight" id="equation-4a8fd78a-49f3-45e8-8a36-44a093e32e9b">
<span class="eqno">(1)<a class="headerlink" href="#equation-4a8fd78a-49f3-45e8-8a36-44a093e32e9b" title="Permalink to this equation">#</a></span>\[\begin{equation}
y = 4 \times x + 1
\end{equation}\]</div>
<p>This equation is linear as it describes a line on a two-dimensional graph. The line comes from plugging in different values into the unknown <span class="math notranslate nohighlight">\(x\)</span> to find out what the model does to the value of <span class="math notranslate nohighlight">\(y\)</span>.</p>
<p>We can have a system of equations with the same form with three unknowns for example:</p>
<div class="amsmath math notranslate nohighlight" id="equation-d58474d0-f50b-4feb-9067-9481a3840010">
<span class="eqno">(2)<a class="headerlink" href="#equation-d58474d0-f50b-4feb-9067-9481a3840010" title="Permalink to this equation">#</a></span>\[\begin{equation}
y = 0.1 \times x_1 + 0.4 \times x_2 \\
y = 0.3 \times x_2 + 0.9 \times x_2 \\
y = 0.2 \times x_1 + 0.3 \times x2
\end{equation}\]</div>
<p>The column of <span class="math notranslate nohighlight">\(y\)</span> values can be taken as a column vector of the outputs from the equation.</p>
<p>The two columns of integer are the data columns, which can be for example <span class="math notranslate nohighlight">\(a_1\)</span> and <span class="math notranslate nohighlight">\(a_2\)</span>, and can be taken as a matrix <span class="math notranslate nohighlight">\(A\)</span>.</p>
<p>The two unknown values <span class="math notranslate nohighlight">\(x_1\)</span> and <span class="math notranslate nohighlight">\(x_2\)</span> can be taken as the coefficients of the equation and form a vector of unknowns <span class="math notranslate nohighlight">\(b\)</span> to be solve. This can be written compactly using linear algebra:</p>
<div class="amsmath math notranslate nohighlight" id="equation-4ff66ef3-c76b-4f2a-9ada-b3170afe2ee6">
<span class="eqno">(3)<a class="headerlink" href="#equation-4ff66ef3-c76b-4f2a-9ada-b3170afe2ee6" title="Permalink to this equation">#</a></span>\[\begin{equation}
y = A \cdot b
\end{equation}\]</div>
<p>However, in real life, we have generally more unknowns than equations to solve, and we often need to approximate the solutions (ie. finding a solution approximating <span class="math notranslate nohighlight">\(y\)</span>).</p>
<section id="vectors">
<h3>Vectors<a class="headerlink" href="#vectors" title="Permalink to this headline">#</a></h3>
<p>Vectors are built from components, which are ordinary numbers. We can think of a vector as a list of numbers and vector algebra as operations performed on the numbers in the list.</p>
<p>Vectors are often represent using a lowercase character, such as <span class="math notranslate nohighlight">\(v\)</span> for example:</p>
<div class="amsmath math notranslate nohighlight" id="equation-b2161a2a-a81d-4e23-b7be-dddcaac0b47e">
<span class="eqno">(4)<a class="headerlink" href="#equation-b2161a2a-a81d-4e23-b7be-dddcaac0b47e" title="Permalink to this equation">#</a></span>\[\begin{equation}
v = \begin{pmatrix}
v1 &amp; v2 &amp; v3
\end{pmatrix}
\end{equation}\]</div>
<p>Where <span class="math notranslate nohighlight">\(v_1\)</span>, <span class="math notranslate nohighlight">\(v_2\)</span> and <span class="math notranslate nohighlight">\(v_3\)</span> are scalar values.</p>
<p>Vectors can also be shown using a column representation:</p>
<div class="amsmath math notranslate nohighlight" id="equation-64a9a9c9-c541-4fb2-8a87-277cf8c628f4">
<span class="eqno">(5)<a class="headerlink" href="#equation-64a9a9c9-c541-4fb2-8a87-277cf8c628f4" title="Permalink to this equation">#</a></span>\[\begin{equation}
v = 
\begin{pmatrix}
v_1 \\
v_2 \\
v_3
\end{pmatrix}
\end{equation}\]</div>
<p>It is a common practice to represent the target variable as a vector with the lowercase <span class="math notranslate nohighlight">\(y\)</span> when describing a ML algorithm.</p>
</section>
<section id="norms">
<h3>Norms<a class="headerlink" href="#norms" title="Permalink to this headline">#</a></h3>
<p>Calculating the length or magnitude of vectors is ofen required either directly as a regularization method in machine learning or as part of broader vector or matrix operations. Vector lengths or magnitude are also called the vector norm. In summary:</p>
<ul class="simple">
<li><p>The <span class="math notranslate nohighlight">\(L^1\)</span> norm is calculated as the sum of the absolute values of the vector</p></li>
<li><p>The <span class="math notranslate nohighlight">\(L^2\)</span> norm is calculated as the square root of the sum of the squared vector values</p></li>
<li><p>The max norm is calculated as the maximum vector values.</p></li>
</ul>
<section id="vector-norm">
<h4>Vector Norm<a class="headerlink" href="#vector-norm" title="Permalink to this headline">#</a></h4>
<p>Calculating the size or length of a vector is often required either directly or as part of a broader vector-matrix opertion. The length of the vector is referred to as the vector norm or the vector’s magnitude.</p>
<p>The length of the vector is always a positive number, expect for a vector of all zero values. It is calculated using some measure that summarizes the distance of the vector from the origin of the vector space.</p>
</section>
<section id="vector-l-1-norm">
<h4>Vector <span class="math notranslate nohighlight">\(L^1\)</span> Norm<a class="headerlink" href="#vector-l-1-norm" title="Permalink to this headline">#</a></h4>
<p>The length of a vector can be calculated using the <span class="math notranslate nohighlight">\(L^1\)</span> norm, where the 1 is a superscript of the <span class="math notranslate nohighlight">\(L\)</span>. The notation for the <span class="math notranslate nohighlight">\(L^1\)</span> norm of a vector is <span class="math notranslate nohighlight">\(||v||_1\)</span>. As such, this length is sometimes called the Manhattan norm.</p>
<div class="amsmath math notranslate nohighlight" id="equation-70df0b8a-dbba-480e-9ec4-891373814711">
<span class="eqno">(6)<a class="headerlink" href="#equation-70df0b8a-dbba-480e-9ec4-891373814711" title="Permalink to this equation">#</a></span>\[\begin{equation}
L^1(v) = ||v||_1
\end{equation}\]</div>
<p>The <span class="math notranslate nohighlight">\(L^1\)</span> norm is calculated as the sum of the absolute vector values, where the absolute value of a scalar uses the notation <span class="math notranslate nohighlight">\(|a_1|\)</span>. In effect, the norm is a calculation of the Manhattan distance from the origin of the vector space:</p>
<div class="amsmath math notranslate nohighlight" id="equation-bfd1a81a-9f26-4692-87e7-94e1e4e9a3c4">
<span class="eqno">(7)<a class="headerlink" href="#equation-bfd1a81a-9f26-4692-87e7-94e1e4e9a3c4" title="Permalink to this equation">#</a></span>\[\begin{equation}
||v||_1 = |a_1| + |a_2| + |a_3|
\end{equation}\]</div>
<p>In many ML applications, it is important to discriminate between elements that are exactly zero and elements that are small but nonzero. In these cases, we turn to a function that grows at the same rate in all locations, but retains mathematical simplicity: the <span class="math notranslate nohighlight">\(L^1\)</span> norm.</p>
<p><em>Example: Let’s have the vector <span class="math notranslate nohighlight">\( a = \begin{pmatrix} 1 &amp; 2 &amp; 3 \end{pmatrix}\)</span>. We have <span class="math notranslate nohighlight">\(L^1(a) = 6\)</span>.</em></p>
<p>The <span class="math notranslate nohighlight">\(L^1\)</span> norm is often used when fitting ML algorithms as a regularization method, ie a method to keep the coefficients of the model small and thus the model less complex.</p>
</section>
<section id="vector-l-2-norm">
<h4>Vector <span class="math notranslate nohighlight">\(L^2\)</span> Norm<a class="headerlink" href="#vector-l-2-norm" title="Permalink to this headline">#</a></h4>
<p>The length of a vector can be calculated using the <span class="math notranslate nohighlight">\(L^2\)</span> norm. The notation for the <span class="math notranslate nohighlight">\(L^2\)</span> norm vector is the following:</p>
<div class="amsmath math notranslate nohighlight" id="equation-e8c0d4df-400e-4637-8dba-4727ec9167aa">
<span class="eqno">(8)<a class="headerlink" href="#equation-e8c0d4df-400e-4637-8dba-4727ec9167aa" title="Permalink to this equation">#</a></span>\[\begin{equation}
L^2(v) = ||v||_2
\end{equation}\]</div>
<p>The <span class="math notranslate nohighlight">\(L^2\)</span> norm calculates the distance of the vector coordinate from the origin of the vector space. As such, it is also known as the Euclidean norm as it is calculated as the Euclidean distance from the origin. The result is a positive distance value. The <span class="math notranslate nohighlight">\(L^2\)</span> norm is calculated as the square root of the sum of the squared vector values:</p>
<div class="amsmath math notranslate nohighlight" id="equation-3b2f3fe3-8945-4468-83c8-dc2b38c8f665">
<span class="eqno">(9)<a class="headerlink" href="#equation-3b2f3fe3-8945-4468-83c8-dc2b38c8f665" title="Permalink to this equation">#</a></span>\[\begin{equation}
||v||_2 = \sqrt{a^2_1 + a_2^2 + a^2_3}
\end{equation}\]</div>
<p><em>Example: For a vector <span class="math notranslate nohighlight">\(a = \begin{pmatrix} 1 &amp; 2 &amp; 3 \end{pmatrix}\)</span>, we have <span class="math notranslate nohighlight">\(L^2(a) \approx 3.74\)</span>.</em></p>
<p>The <span class="math notranslate nohighlight">\(L^2\)</span> norm is also used as a regularization method (keeping the coefficients of the model small). The <span class="math notranslate nohighlight">\(L^2\)</span> norm is the most commonly used vector norms method in ML.</p>
</section>
<section id="vector-max-norm">
<h4>Vector Max Norm<a class="headerlink" href="#vector-max-norm" title="Permalink to this headline">#</a></h4>
<p>The length of a vector can be calculated using the maximum or max norm. It is referred to as <span class="math notranslate nohighlight">\(L^{inf}\)</span>.</p>
<p>The notation is:</p>
<div class="amsmath math notranslate nohighlight" id="equation-7bc3bea9-ab78-474e-a826-b7970976f0ea">
<span class="eqno">(10)<a class="headerlink" href="#equation-7bc3bea9-ab78-474e-a826-b7970976f0ea" title="Permalink to this equation">#</a></span>\[\begin{equation}
L^{inf}(v) = ||v||_{inf}
\end{equation}\]</div>
<p>It is calculated as returning the maximum value of the vector:</p>
<div class="amsmath math notranslate nohighlight" id="equation-890041e8-c793-40d2-a50b-39e17d1f9164">
<span class="eqno">(11)<a class="headerlink" href="#equation-890041e8-c793-40d2-a50b-39e17d1f9164" title="Permalink to this equation">#</a></span>\[\begin{equation}
||v||_{inf} = \max a_1, a_2, a_3
\end{equation}\]</div>
<p><em>Example: For a vector <span class="math notranslate nohighlight">\(a = \begin{pmatrix} 1 &amp; 2 &amp; 3 \end{pmatrix}\)</span>, we have <span class="math notranslate nohighlight">\(L^{inf}(a) = 3\)</span>.</em></p>
<p>It is also used as a regularization method in ML, such as on neural network weights, called max norm regularization.</p>
</section>
</section>
<section id="types-of-matrices">
<h3>Types of Matrices<a class="headerlink" href="#types-of-matrices" title="Permalink to this headline">#</a></h3>
<section id="orthogonal-matrix">
<h4>Orthogonal Matrix<a class="headerlink" href="#orthogonal-matrix" title="Permalink to this headline">#</a></h4>
<p>Two vectors are orthogonal when their dot product equals zero. The length of each vector is 1 then the vector are called orthonormal vecause they are both orthogonal and normalized.</p>
<div class="amsmath math notranslate nohighlight" id="equation-24b26cde-3db4-4b21-b0c3-47d38593428a">
<span class="eqno">(12)<a class="headerlink" href="#equation-24b26cde-3db4-4b21-b0c3-47d38593428a" title="Permalink to this equation">#</a></span>\[\begin{equation}
v \cdot w = 0
\end{equation}\]</div>
<p>An orthogonal matrix is a type of square matrix whose columns and rows are orthonormal unit vectors, ie. perpedicular and have a length of magnitude of 1.</p>
<p>An orthogonal matrix is a square matrix whose rows are mutually orthonormal and whose columns are mutually orthonomal.</p>
<p>An Orthogonal matrix is often denoted as <span class="math notranslate nohighlight">\(Q\)</span>.</p>
<p>The Orthogonal matrix is defined as follows:</p>
<div class="amsmath math notranslate nohighlight" id="equation-87e8a9f5-cb9c-4750-8096-b2bd04602d7c">
<span class="eqno">(13)<a class="headerlink" href="#equation-87e8a9f5-cb9c-4750-8096-b2bd04602d7c" title="Permalink to this equation">#</a></span>\[\begin{equation}
Q^T \cdot Q = Q \cdot Q^T = I
\end{equation}\]</div>
<p>Orthogonal matrices are used a lot for linear transformations, such as reflections and permtations.</p>
<p><em>Example: We have the following orthogonal matrix:</em></p>
<div class="amsmath math notranslate nohighlight" id="equation-25051da8-30bb-49dd-b4fd-27fcb6685708">
<span class="eqno">(14)<a class="headerlink" href="#equation-25051da8-30bb-49dd-b4fd-27fcb6685708" title="Permalink to this equation">#</a></span>\[\begin{equation}
Q = 
\begin{pmatrix}
1 &amp; 0 \\
0 &amp; -1
\end{pmatrix}
\end{equation}\]</div>
<div class="amsmath math notranslate nohighlight" id="equation-ea65535d-2674-4db4-96a0-f7593a16c9bf">
<span class="eqno">(15)<a class="headerlink" href="#equation-ea65535d-2674-4db4-96a0-f7593a16c9bf" title="Permalink to this equation">#</a></span>\[\begin{equation}
Q \cdot Q^T = \begin{pmatrix}
1 &amp; 0 \\
0 &amp; 1 
\end{pmatrix}
\end{equation}\]</div>
</section>
</section>
<section id="matrix-operations">
<h3>Matrix Operations<a class="headerlink" href="#matrix-operations" title="Permalink to this headline">#</a></h3>
<section id="trace">
<h4>Trace<a class="headerlink" href="#trace" title="Permalink to this headline">#</a></h4>
<p>A trace of a square matrix is the sum of the values on the main diagonal of the matrix.</p>
<p>It is described using the notation <span class="math notranslate nohighlight">\(tr(A)\)</span> where <span class="math notranslate nohighlight">\(A\)</span> is the square matrix on which the operation is performed.</p>
<p>The trace is calculated as the sum of the diagonal values, for example in the case of <span class="math notranslate nohighlight">\(3 \times 3\)</span> matrix:</p>
<div class="amsmath math notranslate nohighlight" id="equation-58ca9e5c-d88c-42c2-937b-6d6589dba623">
<span class="eqno">(16)<a class="headerlink" href="#equation-58ca9e5c-d88c-42c2-937b-6d6589dba623" title="Permalink to this equation">#</a></span>\[\begin{equation}
tr(A) = a_{1,1} + a_{2,2} + a_{3,3}
\end{equation}\]</div>
<p><em>Example: we have the following matrix:</em></p>
<div class="amsmath math notranslate nohighlight" id="equation-87b2a6fe-3eee-4be5-9c74-b094223f5dc1">
<span class="eqno">(17)<a class="headerlink" href="#equation-87b2a6fe-3eee-4be5-9c74-b094223f5dc1" title="Permalink to this equation">#</a></span>\[\begin{equation}
A = \begin{pmatrix}
1 &amp; 2 &amp; 3 \\
4 &amp; 5 &amp; 6 \\
7 &amp; 8 &amp; 9
\end{pmatrix}
\end{equation}\]</div>
<div class="amsmath math notranslate nohighlight" id="equation-7597b6bb-1246-4b82-a2e5-d41460f2691a">
<span class="eqno">(18)<a class="headerlink" href="#equation-7597b6bb-1246-4b82-a2e5-d41460f2691a" title="Permalink to this equation">#</a></span>\[\begin{equation}
tr(A) = 15
\end{equation}\]</div>
</section>
<section id="determinant">
<h4>Determinant<a class="headerlink" href="#determinant" title="Permalink to this headline">#</a></h4>
<p>The determinant of a square matrix is a scalar representation of the volume of the matrix.</p>
<p>It is denoted by the <span class="math notranslate nohighlight">\(det(A)\)</span> or <span class="math notranslate nohighlight">\(|A|\)</span> notation, where <span class="math notranslate nohighlight">\(A\)</span> is the matrix on which we are calculating the determinant.</p>
<p>The determinant of a square matrix is calculated from the elements of the matrix.</p>
</section>
</section>
<section id="sparse-matrices">
<h3>Sparse Matrices<a class="headerlink" href="#sparse-matrices" title="Permalink to this headline">#</a></h3>
</section>
</section>
<section id="statistics">
<h2>Statistics<a class="headerlink" href="#statistics" title="Permalink to this headline">#</a></h2>
</section>
<section id="probability">
<h2>Probability<a class="headerlink" href="#probability" title="Permalink to this headline">#</a></h2>
<section id="distributions">
<h3>Distributions<a class="headerlink" href="#distributions" title="Permalink to this headline">#</a></h3>
</section>
<section id="maximum-likelihood">
<h3>Maximum Likelihood<a class="headerlink" href="#maximum-likelihood" title="Permalink to this headline">#</a></h3>
</section>
<section id="bayesian-probability">
<h3>Bayesian Probability<a class="headerlink" href="#bayesian-probability" title="Permalink to this headline">#</a></h3>
</section>
<section id="information-theory">
<h3>Information Theory<a class="headerlink" href="#information-theory" title="Permalink to this headline">#</a></h3>
</section>
<section id="classification">
<h3>Classification<a class="headerlink" href="#classification" title="Permalink to this headline">#</a></h3>
</section>
</section>
<section id="calculus">
<h2>Calculus<a class="headerlink" href="#calculus" title="Permalink to this headline">#</a></h2>
<section id="limits-and-differential-calculus">
<h3>Limits and Differential Calculus<a class="headerlink" href="#limits-and-differential-calculus" title="Permalink to this headline">#</a></h3>
</section>
<section id="multivariate-calculus">
<h3>Multivariate Calculus<a class="headerlink" href="#multivariate-calculus" title="Permalink to this headline">#</a></h3>
</section>
<section id="mathematical-programming">
<h3>Mathematical Programming<a class="headerlink" href="#mathematical-programming" title="Permalink to this headline">#</a></h3>
</section>
<section id="approximation">
<h3>Approximation<a class="headerlink" href="#approximation" title="Permalink to this headline">#</a></h3>
</section>
<section id="gradient-descent">
<h3>Gradient Descent<a class="headerlink" href="#gradient-descent" title="Permalink to this headline">#</a></h3>
</section>
</section>
<section id="optimization">
<h2>Optimization<a class="headerlink" href="#optimization" title="Permalink to this headline">#</a></h2>
</section>
</section>


                </article>
              

              
              
                <footer class="bd-footer-article">
                  <!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="../index.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Factor Models with Machine Learning</p>
      </div>
    </a>
    <a class="right-next"
       href="../TestFramework/intro.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Testing Asset Pricing Models</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#linear-algebra">Linear Algebra</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#vectors">Vectors</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#norms">Norms</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#vector-norm">Vector Norm</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#vector-l-1-norm">Vector <span class="math notranslate nohighlight">\(L^1\)</span> Norm</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#vector-l-2-norm">Vector <span class="math notranslate nohighlight">\(L^2\)</span> Norm</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#vector-max-norm">Vector Max Norm</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#types-of-matrices">Types of Matrices</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#orthogonal-matrix">Orthogonal Matrix</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#matrix-operations">Matrix Operations</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#trace">Trace</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#determinant">Determinant</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sparse-matrices">Sparse Matrices</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#statistics">Statistics</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#probability">Probability</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#distributions">Distributions</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#maximum-likelihood">Maximum Likelihood</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#bayesian-probability">Bayesian Probability</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#information-theory">Information Theory</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#classification">Classification</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#calculus">Calculus</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#limits-and-differential-calculus">Limits and Differential Calculus</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#multivariate-calculus">Multivariate Calculus</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mathematical-programming">Mathematical Programming</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#approximation">Approximation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#gradient-descent">Gradient Descent</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#optimization">Optimization</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            <div class="bd-footer-content__inner">
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Thomas Lorans
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2023, Thomas Lorans.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div></div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=12da95d707ffb74b382d"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=12da95d707ffb74b382d"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>