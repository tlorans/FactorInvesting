

<!DOCTYPE html>


<html >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Project 0: An Introduction to ChatGPT with LangChain &#8212; Climate Risks in Finance 0.1 documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=12da95d707ffb74b382d" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=12da95d707ffb74b382d" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=12da95d707ffb74b382d" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=12da95d707ffb74b382d" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=12da95d707ffb74b382d" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=12da95d707ffb74b382d" />

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'others/intro_langchain';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="None"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
    <p class="title logo__title">Climate Risks in Finance 0.1 documentation</p>
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../intro/lowcarbon.html">Portfolio Decarbonization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intro/net_zero.html">Towards a Net Zero Strategy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intro/intro_langchain_v2.html">Project 0: Information Extraction with ChatGPT</a></li>
<li class="toctree-l1"><a class="reference internal" href="../climate_investing/net_zero_investing.html">Net Zero Investing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../climate_investing/portfolio_decarbonization_pathway.html">Portfolio Decarbonization Pathway</a></li>
<li class="toctree-l1"><a class="reference internal" href="../climate_investing/portfolio_alignment.html">Portfolio Alignment</a></li>
<li class="toctree-l1"><a class="reference internal" href="../climate_investing/project1.html">Project 1: Emissions Data Search with ChatGPT</a></li>
<li class="toctree-l1"><a class="reference internal" href="../climate_investing/project_2.html">Project 2: Estimating Emissions with ChatGPT</a></li>
<li class="toctree-l1"><a class="reference internal" href="../climate_investing/self_decarbonization.html">Net Zero Backtesting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../climate_investing/integratingtransition.html">Integrating the Transition Dimension</a></li>
<li class="toctree-l1"><a class="reference internal" href="../references.html">References</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/others/intro_langchain.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Project 0: An Introduction to ChatGPT with LangChain</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain">LangChain</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#first-prompts">First Prompts</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#multiple-questions">Multiple Questions</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#prompt-engineering-with-langchain">Prompt Engineering with LangChain</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#prompt-engineering">Prompt Engineering</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#prompt-templates">Prompt Templates</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction-to-templates">Introduction to Templates</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#output-parsers">Output Parsers</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#few-shot-prompt-learning">Few Shot Prompt Learning</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#memory">Memory</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#conversationchain">ConversationChain</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise">Exercise</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="project-0-an-introduction-to-chatgpt-with-langchain">
<h1>Project 0: An Introduction to ChatGPT with LangChain<a class="headerlink" href="#project-0-an-introduction-to-chatgpt-with-langchain" title="Permalink to this headline">#</a></h1>
<p>Large Language Models (LLMs) have enjoyed a growth in popularity since the release of OpenAI’s GPT-3 in 2020 (Brown et al., 2020 <span id="id1">[<a class="reference internal" href="../references.html#id37" title="Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, and others. Language models are few-shot learners. Advances in neural information processing systems, 33:1877–1901, 2020.">BMR+20</a>]</span>).</p>
<p>After further impressive improvements in LLMs, those models gained the non-specialists when OpenAI released <code class="docutils literal notranslate"><span class="pre">ChatGPT</span></code>.</p>
<p>At the same time, <code class="docutils literal notranslate"><span class="pre">LangChain</span></code> appeared. This open-source development framework has incredible features for building tools around LLMs.</p>
<p>In this part, we are going to introduce this library and start with straightforward interactions with <code class="docutils literal notranslate"><span class="pre">ChatGPT</span></code>.</p>
<section id="langchain">
<h2>LangChain<a class="headerlink" href="#langchain" title="Permalink to this headline">#</a></h2>
<p><code class="docutils literal notranslate"><span class="pre">LangChain</span></code> is a development framework built around LLMs. The core idea of the library is the chain of different components (modularity) to create advanced use cases with LLMs.</p>
<p>Chains consists of multiple components from modules such as:</p>
<ul class="simple">
<li><p>Prompt templates</p></li>
<li><p>LLMs</p></li>
<li><p>Agents</p></li>
<li><p>Memory</p></li>
</ul>
</section>
<section id="first-prompts">
<h2>First Prompts<a class="headerlink" href="#first-prompts" title="Permalink to this headline">#</a></h2>
<p>We’ll strart with some basics behind prompt templates for <code class="docutils literal notranslate"><span class="pre">ChatGPT</span></code>.</p>
<p>Prompts are often structured in different ways so that we can get different results.</p>
<p>Let’s begin with a simple question-answering prompt template.</p>
<p>We first need to install the <code class="docutils literal notranslate"><span class="pre">langchain</span></code> and <code class="docutils literal notranslate"><span class="pre">openai</span></code> libraries:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span>!pip install langchain
!pip install openai
</pre></div>
</div>
<p>We also need to load our API key:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;OPENAI_API_KEY&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">openai_api_key</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;key.txt&#39;</span><span class="p">,</span><span class="s1">&#39;r&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
</pre></div>
</div>
<p>From here, we can import the <code class="docutils literal notranslate"><span class="pre">ChatPromptTemplate</span></code> class and initialize a template like so:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.prompts</span> <span class="kn">import</span> <span class="n">ChatPromptTemplate</span>

<span class="n">template</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;Question: </span><span class="si">{question}</span><span class="s2"></span>
<span class="s2">Answer: &quot;&quot;&quot;</span>

<span class="n">prompt</span> <span class="o">=</span> <span class="n">ChatPromptTemplate</span><span class="o">.</span><span class="n">from_template</span><span class="p">(</span><span class="n">template</span><span class="p">)</span>

<span class="n">question</span> <span class="o">=</span> <span class="s2">&quot;Which country emits the most GHG emissions?&quot;</span>
</pre></div>
</div>
<p>Now, we can create our first <code class="docutils literal notranslate"><span class="pre">LLMChain</span></code> and obtain our first answer:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.chat_models</span> <span class="kn">import</span> <span class="n">ChatOpenAI</span>

<span class="n">chat</span> <span class="o">=</span> <span class="n">ChatOpenAI</span><span class="p">(</span><span class="n">temperature</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
                  <span class="p">)</span>


<span class="kn">from</span> <span class="nn">langchain</span> <span class="kn">import</span> <span class="n">LLMChain</span>

<span class="n">llm_chain</span> <span class="o">=</span> <span class="n">LLMChain</span><span class="p">(</span>
    <span class="n">prompt</span> <span class="o">=</span> <span class="n">prompt</span><span class="p">,</span>
    <span class="n">llm</span> <span class="o">=</span> <span class="n">chat</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">llm_chain</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">question</span><span class="p">))</span>
</pre></div>
</div>
<p>And the answer we get is:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">As</span> <span class="n">an</span> <span class="n">AI</span> <span class="n">language</span> <span class="n">model</span><span class="p">,</span> <span class="n">I</span> <span class="n">do</span> <span class="ow">not</span> <span class="n">have</span> <span class="n">access</span> <span class="n">to</span> <span class="n">the</span> <span class="n">latest</span> <span class="n">data</span><span class="o">.</span> <span class="n">However</span><span class="p">,</span> <span class="n">according</span> <span class="n">to</span> <span class="n">the</span> <span class="n">latest</span> <span class="n">available</span> <span class="n">data</span> <span class="kn">from</span> <span class="mi">2019</span><span class="p">,</span> <span class="n">China</span> <span class="ow">is</span> <span class="n">the</span> <span class="n">country</span> <span class="n">that</span> <span class="n">emits</span> <span class="n">the</span> <span class="n">most</span> <span class="n">greenhouse</span> <span class="n">gas</span> <span class="n">emissions</span><span class="p">,</span> <span class="n">followed</span> <span class="n">by</span> <span class="n">the</span> <span class="n">United</span> <span class="n">States</span> <span class="ow">and</span> <span class="n">India</span><span class="o">.</span>
</pre></div>
</div>
<section id="multiple-questions">
<h3>Multiple Questions<a class="headerlink" href="#multiple-questions" title="Permalink to this headline">#</a></h3>
<p>If we want to ask multiple questions, there is two approaches:</p>
<ol class="arabic simple">
<li><p>Iterate through all questions using the <code class="docutils literal notranslate"><span class="pre">generate</span></code> method, answering them one at a time</p></li>
<li><p>Place all questions into a single prompt.</p></li>
</ol>
<p>Let’s tests with the first option:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">qs</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">{</span><span class="s1">&#39;question&#39;</span><span class="p">:</span> <span class="s2">&quot;Which country emits the most GHG emissions?&quot;</span><span class="p">},</span>
    <span class="p">{</span><span class="s1">&#39;question&#39;</span><span class="p">:</span> <span class="s2">&quot;What Scope 1, 2 and 3 emissions are?&quot;</span><span class="p">},</span>
    <span class="p">{</span><span class="s1">&#39;question&#39;</span><span class="p">:</span> <span class="s2">&quot;What are Climate Risks?&quot;</span><span class="p">},</span>
<span class="p">]</span>
<span class="n">res</span> <span class="o">=</span> <span class="n">llm_chain</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">qs</span><span class="p">)</span>
<span class="n">res</span>
</pre></div>
</div>
<p>And we get:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">LLMResult</span><span class="p">(</span><span class="n">generations</span><span class="o">=</span><span class="p">[[</span><span class="n">ChatGeneration</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="s1">&#39;As of 2021, China is the country that emits the most greenhouse gas (GHG) emissions, followed by the United States, India, Russia, and Japan.&#39;</span><span class="p">,</span> <span class="n">generation_info</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">message</span><span class="o">=</span><span class="n">AIMessage</span><span class="p">(</span><span class="n">content</span><span class="o">=</span><span class="s1">&#39;As of 2021, China is the country that emits the most greenhouse gas (GHG) emissions, followed by the United States, India, Russia, and Japan.&#39;</span><span class="p">,</span> <span class="n">additional_kwargs</span><span class="o">=</span><span class="p">{},</span> <span class="n">example</span><span class="o">=</span><span class="kc">False</span><span class="p">))],</span> <span class="p">[</span><span class="n">ChatGeneration</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="s1">&#39;Scope 1, 2, and 3 emissions are categories used to classify greenhouse gas emissions. </span><span class="se">\n\n</span><span class="s1">Scope 1 emissions refer to direct emissions from sources that are owned or controlled by the reporting entity, such as emissions from combustion of fossil fuels in boilers or vehicles.</span><span class="se">\n\n</span><span class="s1">Scope 2 emissions refer to indirect emissions from the consumption of purchased electricity, heat, or steam.</span><span class="se">\n\n</span><span class="s1">Scope 3 emissions refer to all other indirect emissions that occur in the value chain of the reporting entity, including emissions from the production of purchased goods and services, transportation of goods, and employee commuting.&#39;</span><span class="p">,</span> <span class="n">generation_info</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">message</span><span class="o">=</span><span class="n">AIMessage</span><span class="p">(</span><span class="n">content</span><span class="o">=</span><span class="s1">&#39;Scope 1, 2, and 3 emissions are categories used to classify greenhouse gas emissions. </span><span class="se">\n\n</span><span class="s1">Scope 1 emissions refer to direct emissions from sources that are owned or controlled by the reporting entity, such as emissions from combustion of fossil fuels in boilers or vehicles.</span><span class="se">\n\n</span><span class="s1">Scope 2 emissions refer to indirect emissions from the consumption of purchased electricity, heat, or steam.</span><span class="se">\n\n</span><span class="s1">Scope 3 emissions refer to all other indirect emissions that occur in the value chain of the reporting entity, including emissions from the production of purchased goods and services, transportation of goods, and employee commuting.&#39;</span><span class="p">,</span> <span class="n">additional_kwargs</span><span class="o">=</span><span class="p">{},</span> <span class="n">example</span><span class="o">=</span><span class="kc">False</span><span class="p">))],</span> <span class="p">[</span><span class="n">ChatGeneration</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="s1">&#39;Climate risks refer to the potential negative impacts of climate change on human and natural systems. These risks can include more frequent and severe weather events such as floods, droughts, and heatwaves, as well as rising sea levels, ocean acidification, and loss of biodiversity. Climate risks can also have economic and social impacts, such as reduced agricultural productivity, increased healthcare costs, and displacement of communities due to extreme weather events or sea level rise.&#39;</span><span class="p">,</span> <span class="n">generation_info</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">message</span><span class="o">=</span><span class="n">AIMessage</span><span class="p">(</span><span class="n">content</span><span class="o">=</span><span class="s1">&#39;Climate risks refer to the potential negative impacts of climate change on human and natural systems. These risks can include more frequent and severe weather events such as floods, droughts, and heatwaves, as well as rising sea levels, ocean acidification, and loss of biodiversity. Climate risks can also have economic and social impacts, such as reduced agricultural productivity, increased healthcare costs, and displacement of communities due to extreme weather events or sea level rise.&#39;</span><span class="p">,</span> <span class="n">additional_kwargs</span><span class="o">=</span><span class="p">{},</span> <span class="n">example</span><span class="o">=</span><span class="kc">False</span><span class="p">))]],</span> <span class="n">llm_output</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;token_usage&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;prompt_tokens&#39;</span><span class="p">:</span> <span class="mi">67</span><span class="p">,</span> <span class="s1">&#39;completion_tokens&#39;</span><span class="p">:</span> <span class="mi">237</span><span class="p">,</span> <span class="s1">&#39;total_tokens&#39;</span><span class="p">:</span> <span class="mi">304</span><span class="p">},</span> <span class="s1">&#39;model_name&#39;</span><span class="p">:</span> <span class="s1">&#39;gpt-3.5-turbo&#39;</span><span class="p">})</span>
</pre></div>
</div>
<p>We can also test the option 2:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">multi_template</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;Answer the following questions one at a time.</span>

<span class="s2">Questions:</span>
<span class="si">{questions}</span><span class="s2"></span>

<span class="s2">Answers:</span>
<span class="s2">&quot;&quot;&quot;</span>

<span class="n">long_prompt</span> <span class="o">=</span> <span class="n">ChatPromptTemplate</span><span class="o">.</span><span class="n">from_template</span><span class="p">(</span><span class="n">multi_template</span><span class="p">)</span>

<span class="n">llm_chain</span> <span class="o">=</span> <span class="n">LLMChain</span><span class="p">(</span>
    <span class="n">prompt</span> <span class="o">=</span> <span class="n">long_prompt</span><span class="p">,</span>
    <span class="n">llm</span> <span class="o">=</span> <span class="n">chat</span>
<span class="p">)</span>

<span class="n">qs_str</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Which country emits the most GHG emissions?</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">+</span>
    <span class="s2">&quot;What Scope 1, 2 and 3 emissions are?</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">+</span>
     <span class="s2">&quot;What are Climate Risks?&quot;</span>
<span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="n">llm_chain</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">qs_str</span><span class="p">))</span>
</pre></div>
</div>
<p>And the result is:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>1. Which country emits the most GHG emissions?
- According to recent data, China is currently the country that emits the most greenhouse gas (GHG) emissions, followed by the United States and India.

2. What Scope 1, 2 and 3 emissions are?
- Scope 1, 2 and 3 emissions are categories used to classify greenhouse gas (GHG) emissions. Scope 1 emissions refer to direct emissions from sources that are owned or controlled by a company, such as emissions from combustion of fossil fuels. Scope 2 emissions refer to indirect emissions from the generation of purchased electricity, heat or steam. Scope 3 emissions refer to all other indirect emissions that occur in a company&#39;s value chain, such as emissions from the production of purchased goods and services, employee commuting, and waste disposal.

3. What are Climate Risks?
- Climate risks refer to the potential negative impacts of climate change on human and natural systems. These risks can include more frequent and severe weather events, sea level rise, changes in precipitation patterns, and impacts on ecosystems and biodiversity. Climate risks can have significant economic, social and environmental consequences, and are a major concern for governments, businesses and communities around the world.
</pre></div>
</div>
</section>
</section>
<section id="prompt-engineering-with-langchain">
<h2>Prompt Engineering with LangChain<a class="headerlink" href="#prompt-engineering-with-langchain" title="Permalink to this headline">#</a></h2>
<p>In Natural Language Processing (NLP), we used to train different models for different tasks.</p>
<p>With the versatility of LLMs, this has changed. The time when we needed separate models for classification, named entity recognition (NER) or question-answering (QA) is over.</p>
<p>With the introduction of transformers model and transfer learning, all that was needed to adapt a language model for different tasks was a few small layers at the end of the network (the head) and fine-tuning.</p>
<p>Today, even this approach is outdated. Rather than changing these last few model layers and go through a fine-tuning process, we can now prompt the model to do classification or QA.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">LangChain</span></code> library puts this prompt engineering at the center, and has built an entire set of objects for them.</p>
<p>In this section, we are going to focus on <code class="docutils literal notranslate"><span class="pre">ChatPromptTemplate</span></code> and how implementing them effectively.</p>
<section id="prompt-engineering">
<h3>Prompt Engineering<a class="headerlink" href="#prompt-engineering" title="Permalink to this headline">#</a></h3>
<p>A prompt is typically composed of multiple parts:</p>
<ul class="simple">
<li><p>Instructions: tell the model what to do, how to use external information and how to construct the output</p></li>
<li><p>External information: context as an additional source of knowledge for the model. It can be manually inserted or retrieved via an external database</p></li>
<li><p>User input or query: a query input by the human user</p></li>
<li><p>Output indicator: it is the beginning of the future generated text. If generating Python code for example, we can use <code class="docutils literal notranslate"><span class="pre">import</span></code> to indicate the model it must begin writing Python code</p></li>
</ul>
<p>Each component is usually placed in the prompt in that order.</p>
<p>Let’s test it:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">prompt</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;Answer the question based on the context below. If the</span>
<span class="s2">question cannot be answered using the information provided answer</span>
<span class="s2">with &quot;I don&#39;t know&quot;.</span>

<span class="s2">Context: Transitioning to a lower-carbon economy may entail extensive policy, legal, technology, and</span>
<span class="s2">market changes to address mitigation and adaptation requirements related to climate change.</span>
<span class="s2">Depending on the nature, speed, and focus of these changes, transition risks may pose varying</span>
<span class="s2">levels of financial and reputational risk to organizations.</span>

<span class="s2">Question: What market changes entailed by the transition towards a low-carbon economy?</span>

<span class="s2">Answer: &quot;&quot;&quot;</span>

<span class="n">template</span> <span class="o">=</span> <span class="n">ChatPromptTemplate</span><span class="o">.</span><span class="n">from_template</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">chat</span><span class="p">(</span><span class="n">template</span><span class="o">.</span><span class="n">format_messages</span><span class="p">())</span><span class="o">.</span><span class="n">content</span><span class="p">)</span>
</pre></div>
</div>
<p>And the answer is:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">The</span> <span class="n">context</span> <span class="n">mentions</span> <span class="n">that</span> <span class="n">transitioning</span> <span class="n">to</span> <span class="n">a</span> <span class="n">lower</span><span class="o">-</span><span class="n">carbon</span> <span class="n">economy</span> <span class="n">may</span> <span class="n">entail</span> <span class="n">extensive</span> <span class="n">market</span> <span class="n">changes</span><span class="p">,</span> <span class="n">but</span> <span class="n">it</span> <span class="n">does</span> <span class="ow">not</span> <span class="n">provide</span> <span class="n">specific</span> <span class="n">details</span> <span class="n">on</span> <span class="n">what</span> <span class="n">those</span> <span class="n">changes</span> <span class="n">may</span> <span class="n">be</span><span class="o">.</span> <span class="n">Therefore</span><span class="p">,</span> <span class="n">the</span> <span class="n">answer</span> <span class="ow">is</span> <span class="s2">&quot;I don&#39;t know.&quot;</span>
</pre></div>
</div>
<p>In reality, we don’t want to hardcore the context and user question. We are going to use a template to generate it.</p>
</section>
<section id="prompt-templates">
<h3>Prompt Templates<a class="headerlink" href="#prompt-templates" title="Permalink to this headline">#</a></h3>
<section id="introduction-to-templates">
<h4>Introduction to Templates<a class="headerlink" href="#introduction-to-templates" title="Permalink to this headline">#</a></h4>
<p>Prompt template classes in <code class="docutils literal notranslate"><span class="pre">LangChain</span></code> are built to make constructing prompts with dynamic inputs easier.</p>
<p>We can test this by adding a single dynamic input, the user query:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.prompts</span> <span class="kn">import</span> <span class="n">ChatPromptTemplate</span>

<span class="n">template</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;Answer the question based on the context below. If the</span>
<span class="s2">question cannot be answered using the information provided answer</span>
<span class="s2">with &quot;I don&#39;t know&quot;.</span>

<span class="s2">Context: Transitioning to a lower-carbon economy may entail extensive policy, legal, technology, and</span>
<span class="s2">market changes to address mitigation and adaptation requirements related to climate change.</span>
<span class="s2">Depending on the nature, speed, and focus of these changes, transition risks may pose varying</span>
<span class="s2">levels of financial and reputational risk to organizations.</span>

<span class="s2">Question: </span><span class="si">{query}</span><span class="s2"></span>

<span class="s2">Answer: &quot;&quot;&quot;</span>

<span class="n">prompt_template</span> <span class="o">=</span> <span class="n">ChatPromptTemplate</span><span class="o">.</span><span class="n">from_template</span><span class="p">(</span><span class="n">template</span><span class="p">)</span>
</pre></div>
</div>
<p>When we use the <code class="docutils literal notranslate"><span class="pre">format_messages</span></code> from our <code class="docutils literal notranslate"><span class="pre">ChatPromptTemplate</span></code>, we need to pass the query:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">message</span> <span class="o">=</span> <span class="n">prompt_template</span><span class="o">.</span><span class="n">format_messages</span><span class="p">(</span><span class="n">query</span> <span class="o">=</span> <span class="s2">&quot;What are the market changes entailed by the transition towards a low-carbon economy?&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">message</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">content</span><span class="p">)</span>
</pre></div>
</div>
<p>It gives:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>Answer the question based on the context below. If the
question cannot be answered using the information provided answer
with &quot;I don&#39;t know&quot;.

Context: Transitioning to a lower-carbon economy may entail extensive policy, legal, technology, and
market changes to address mitigation and adaptation requirements related to climate change.
Depending on the nature, speed, and focus of these changes, transition risks may pose varying
levels of financial and reputational risk to organizations.

Question: What are the market changes entailed by the transition towards a low-carbon economy?

Answer: 
</pre></div>
</div>
</section>
<section id="output-parsers">
<h4>Output Parsers<a class="headerlink" href="#output-parsers" title="Permalink to this headline">#</a></h4>
<p>Answers from <code class="docutils literal notranslate"><span class="pre">ChatGPT</span></code> are obtained as string. However, we may want to obtain it in a more specific format for further treatments.</p>
<p>For example, you may want to obtain a Python list:</p>
<div class="highlight-JSON notranslate"><div class="highlight"><pre><span></span>{
  &quot;answer&quot;: [&#39;China&#39;,&#39;United States&#39;]
}
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">langchain</span></code> library proposes output parsers with the <code class="docutils literal notranslate"><span class="pre">ResponseSchema</span></code> and <code class="docutils literal notranslate"><span class="pre">StructuredOutputParser</span></code>.</p>
<p>First, we need to add format instructions to the prompt:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.output_parsers</span> <span class="kn">import</span> <span class="n">ResponseSchema</span>
<span class="kn">from</span> <span class="nn">langchain.output_parsers</span> <span class="kn">import</span> <span class="n">StructuredOutputParser</span>

<span class="n">response_schemas</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">ResponseSchema</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&quot;answer&quot;</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="s2">&quot;answer to the user&#39;s question.</span><span class="se">\</span>
<span class="s2">    output it as a comma separated Python list, such as [&#39;country_1&#39;,&#39;country_2&#39;]&quot;</span><span class="p">),</span>
<span class="p">]</span>


<span class="n">output_parser</span> <span class="o">=</span> <span class="n">StructuredOutputParser</span><span class="o">.</span><span class="n">from_response_schemas</span><span class="p">(</span><span class="n">response_schemas</span><span class="p">)</span>
<span class="n">format_instructions</span> <span class="o">=</span> <span class="n">output_parser</span><span class="o">.</span><span class="n">get_format_instructions</span><span class="p">()</span>

<span class="n">template_format</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span><span class="si">{query}</span><span class="se">\n\</span>

<span class="si">{format_instructions}</span><span class="s2"></span>
<span class="s2">&quot;&quot;&quot;</span>

<span class="n">prompt</span> <span class="o">=</span> <span class="n">ChatPromptTemplate</span><span class="o">.</span><span class="n">from_template</span><span class="p">(</span><span class="n">template_format</span><span class="p">)</span>
<span class="n">messages</span> <span class="o">=</span> <span class="n">prompt</span><span class="o">.</span><span class="n">format_messages</span><span class="p">(</span><span class="n">query</span> <span class="o">=</span> <span class="s2">&quot;What are the top 5 countries that produce the most carbon dioxide?&quot;</span><span class="p">,</span>
                                <span class="n">format_instructions</span> <span class="o">=</span> <span class="n">format_instructions</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">messages</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">content</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>What are the top 5 countries that produce the most carbon dioxide?

The output should be a markdown code snippet formatted in the following schema, including the leading and trailing &quot;\`\`\`json&quot; and &quot;\`\`\`&quot;:

{
	&quot;answer&quot;: string  // answer to the user&#39;s question.    output it as a comma separated Python list, such as [&#39;country_1&#39;,&#39;country_2&#39;]
}
</pre></div>
</div>
<p>Now we can use the output parser to get the Python list:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">response</span> <span class="o">=</span> <span class="n">chat</span><span class="p">(</span><span class="n">messages</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">output_parser</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">content</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="p">[</span><span class="s1">&#39;answer&#39;</span><span class="p">])</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="s1">&#39;China&#39;</span><span class="p">,</span> <span class="s1">&#39;United States&#39;</span><span class="p">,</span> <span class="s1">&#39;India&#39;</span><span class="p">,</span> <span class="s1">&#39;Russia&#39;</span><span class="p">,</span> <span class="s1">&#39;Japan&#39;</span><span class="p">]</span>
</pre></div>
</div>
</section>
<section id="few-shot-prompt-learning">
<h4>Few Shot Prompt Learning<a class="headerlink" href="#few-shot-prompt-learning" title="Permalink to this headline">#</a></h4>
<p>LLMs success comes from their ability to store knowledge within the model parameters, learned during model training.</p>
<p>However, there are ways to pass more knowledge to an LLM:</p>
<ol class="arabic simple">
<li><p>Parametric knowledge: the knowledge mentioned above is anything that has been learned by the model during training time and stored within the model weights</p></li>
<li><p>Source knowledge: any knowledge provided to the model at inference time via the prompt</p></li>
</ol>
<p>Few shot prompt learning aims to add source knowledge to the prompt. The idea is to train the model on a few examples (few-shot learning).</p>
<p>With <code class="docutils literal notranslate"><span class="pre">ChatGPT</span></code>, this is mostly done by giving instructions via Human / AI interaction.</p>
<p>Rather than starting directly with <code class="docutils literal notranslate"><span class="pre">ChartPromptTemplate</span></code>, we need to decompose our prompt template construction with:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">SystemMessagePromptTemplate</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">AIMessagePromptTemplate</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">HumanMessagePromptTemplate</span></code></p></li>
</ul>
<p>It will generate:</p>
<ul class="simple">
<li><p>a <code class="docutils literal notranslate"><span class="pre">SystemMessage</span></code></p></li>
<li><p>an <code class="docutils literal notranslate"><span class="pre">AIMessage</span></code></p></li>
<li><p>a <code class="docutils literal notranslate"><span class="pre">HumanMessage</span></code></p></li>
</ul>
<p>These messages will be used to create the <code class="docutils literal notranslate"><span class="pre">ChatPromptTemplate</span></code> using this time the <code class="docutils literal notranslate"><span class="pre">from_messages</span></code> method.</p>
<p>Let’s have an illustration:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.chat_models</span> <span class="kn">import</span> <span class="n">ChatOpenAI</span>
<span class="kn">from</span> <span class="nn">langchain</span> <span class="kn">import</span> <span class="n">PromptTemplate</span><span class="p">,</span> <span class="n">LLMChain</span>
<span class="kn">from</span> <span class="nn">langchain.prompts.chat</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">ChatPromptTemplate</span><span class="p">,</span>
    <span class="n">SystemMessagePromptTemplate</span><span class="p">,</span>
    <span class="n">AIMessagePromptTemplate</span><span class="p">,</span>
    <span class="n">HumanMessagePromptTemplate</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">langchain.schema</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">AIMessage</span><span class="p">,</span>
    <span class="n">HumanMessage</span><span class="p">,</span>
    <span class="n">SystemMessage</span>
<span class="p">)</span>

<span class="n">template</span><span class="o">=</span><span class="s2">&quot;You are a helpful assistant that provides provides ranking of countries.&quot;</span>
<span class="n">system_message_prompt</span> <span class="o">=</span> <span class="n">SystemMessagePromptTemplate</span><span class="o">.</span><span class="n">from_template</span><span class="p">(</span><span class="n">template</span><span class="p">)</span>
<span class="n">example_human</span> <span class="o">=</span> <span class="n">HumanMessagePromptTemplate</span><span class="o">.</span><span class="n">from_template</span><span class="p">(</span><span class="s2">&quot;What are the </span><span class="se">\</span>
<span class="s2">top 3 richest countries in the World by GNI per Capita?&quot;</span><span class="p">)</span>
<span class="n">example_ai</span> <span class="o">=</span> <span class="n">AIMessagePromptTemplate</span><span class="o">.</span><span class="n">from_template</span><span class="p">(</span><span class="s2">&quot;1. Liechtenstein,</span><span class="se">\n\</span>
<span class="s2">2. Switzerland</span><span class="se">\n\</span>
<span class="s2">3. Luxembourg&quot;</span><span class="p">)</span>
<span class="n">human_template</span><span class="o">=</span><span class="s2">&quot;</span><span class="si">{text}</span><span class="s2">&quot;</span>
<span class="n">human_message_prompt</span> <span class="o">=</span> <span class="n">HumanMessagePromptTemplate</span><span class="o">.</span><span class="n">from_template</span><span class="p">(</span><span class="n">human_template</span><span class="p">)</span>
<span class="n">chat_prompt</span> <span class="o">=</span> <span class="n">ChatPromptTemplate</span><span class="o">.</span><span class="n">from_messages</span><span class="p">([</span><span class="n">system_message_prompt</span><span class="p">,</span> <span class="n">example_human</span><span class="p">,</span> <span class="n">example_ai</span><span class="p">,</span> <span class="n">human_message_prompt</span><span class="p">])</span>
<span class="n">chain</span> <span class="o">=</span> <span class="n">LLMChain</span><span class="p">(</span><span class="n">llm</span><span class="o">=</span><span class="n">chat</span><span class="p">,</span> <span class="n">prompt</span><span class="o">=</span><span class="n">chat_prompt</span><span class="p">)</span>
<span class="c1"># get a chat completion from the formatted messages</span>
<span class="nb">print</span><span class="p">(</span><span class="n">chain</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="s2">&quot;What are the top 5 Oil producers countries?&quot;</span><span class="p">))</span>
</pre></div>
</div>
<p>And the asnwer is:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">The</span> <span class="n">top</span> <span class="mi">5</span> <span class="n">oil</span><span class="o">-</span><span class="n">producing</span> <span class="n">countries</span> <span class="ow">in</span> <span class="n">the</span> <span class="n">world</span> <span class="n">are</span><span class="p">:</span>

<span class="mf">1.</span> <span class="n">United</span> <span class="n">States</span>
<span class="mf">2.</span> <span class="n">Saudi</span> <span class="n">Arabia</span>
<span class="mf">3.</span> <span class="n">Russia</span>
<span class="mf">4.</span> <span class="n">Canada</span>
<span class="mf">5.</span> <span class="n">China</span>
</pre></div>
</div>
</section>
</section>
</section>
<section id="memory">
<h2>Memory<a class="headerlink" href="#memory" title="Permalink to this headline">#</a></h2>
<p>Conversational memory is what allows a chatbot to response to multiple queries in a coherent conversation. Without it, every new query is treated as an independent input without considering past interactions.</p>
<p>By default, LLMs are stateless. It means that each query is processed independently of other interactions.</p>
<p>However, in many cases it can be interesting that LLMs remember previous interaction.</p>
<p>In the <code class="docutils literal notranslate"><span class="pre">langchain</span></code> library, conversational memory is done through the use of <code class="docutils literal notranslate"><span class="pre">ConversationChain</span></code> classes.</p>
<section id="conversationchain">
<h3>ConversationChain<a class="headerlink" href="#conversationchain" title="Permalink to this headline">#</a></h3>
<p>We can start by initializing the <code class="docutils literal notranslate"><span class="pre">ConversationChain</span></code>:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.chains</span> <span class="kn">import</span> <span class="n">ConversationChain</span>

<span class="n">llm</span> <span class="o">=</span> <span class="n">ChatOpenAI</span><span class="p">(</span><span class="n">temperature</span> <span class="o">=</span> <span class="mf">0.</span><span class="p">)</span>

<span class="n">conversation</span> <span class="o">=</span> <span class="n">ConversationChain</span><span class="p">(</span><span class="n">llm</span> <span class="o">=</span> <span class="n">llm</span><span class="p">)</span>
</pre></div>
</div>
<p>We can see the prompt template used by the <code class="docutils literal notranslate"><span class="pre">ConversationChain</span></code>:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">conversation</span><span class="o">.</span><span class="n">prompt</span><span class="o">.</span><span class="n">template</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">The</span> <span class="n">following</span> <span class="ow">is</span> <span class="n">a</span> <span class="n">friendly</span> <span class="n">conversation</span> <span class="n">between</span> <span class="n">a</span> <span class="n">human</span> <span class="ow">and</span> <span class="n">an</span> <span class="n">AI</span><span class="o">.</span> <span class="n">The</span> <span class="n">AI</span> <span class="ow">is</span> <span class="n">talkative</span> <span class="ow">and</span> <span class="n">provides</span> <span class="n">lots</span> <span class="n">of</span> <span class="n">specific</span> <span class="n">details</span> <span class="kn">from</span> <span class="nn">its</span> <span class="n">context</span><span class="o">.</span> <span class="n">If</span> <span class="n">the</span> <span class="n">AI</span> <span class="n">does</span> <span class="ow">not</span> <span class="n">know</span> <span class="n">the</span> <span class="n">answer</span> <span class="n">to</span> <span class="n">a</span> <span class="n">question</span><span class="p">,</span> <span class="n">it</span> <span class="n">truthfully</span> <span class="n">says</span> <span class="n">it</span> <span class="n">does</span> <span class="ow">not</span> <span class="n">know</span><span class="o">.</span>

<span class="n">Current</span> <span class="n">conversation</span><span class="p">:</span>
<span class="p">{</span><span class="n">history</span><span class="p">}</span>
<span class="n">Human</span><span class="p">:</span> <span class="p">{</span><span class="nb">input</span><span class="p">}</span>
<span class="n">AI</span><span class="p">:</span>
</pre></div>
</div>
<p>Here the prompts tells to the model that it is a conversation between a user and an AI. We see two parameters: <code class="docutils literal notranslate"><span class="pre">{history}</span></code> and <code class="docutils literal notranslate"><span class="pre">{input}</span></code>.</p>
<p>In the <code class="docutils literal notranslate"><span class="pre">{input}</span></code> will be placed the latest human query, while the <code class="docutils literal notranslate"><span class="pre">{history}</span></code> is where conversational memory is used.</p>
<p>We can test it:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">conversation</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="s2">&quot;My name is Thomas&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>Hello Thomas! It&#39;s nice to meet you. Is there anything I can help you with today?
</pre></div>
</div>
<p>Does it remembers my name?</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">conversation</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="s2">&quot;What is my name?&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>Your name is Thomas, as you just told me. Is there anything else you would like to know?
</pre></div>
</div>
</section>
</section>
<section id="exercise">
<h2>Exercise<a class="headerlink" href="#exercise" title="Permalink to this headline">#</a></h2>
<p>We are going to test if <code class="docutils literal notranslate"><span class="pre">ChatGPT</span></code> can be useful for information extraction (IE).</p>
<p>Short answer: it is, as confirmed by Wei et al. (2023) <span id="id2">[<a class="reference internal" href="../references.html#id36" title="Xiang Wei, Xingyu Cui, Ning Cheng, Xiaobin Wang, Xin Zhang, Shen Huang, Pengjun Xie, Jinan Xu, Yufeng Chen, Meishan Zhang, and others. Zero-shot information extraction via chatting with chatgpt. arXiv preprint arXiv:2302.10205, 2023.">WCC+23</a>]</span> for zero-shot IE or Shi et al. (2023) <span id="id3">[<a class="reference internal" href="../references.html#id38" title="Yucheng Shi, Hehuan Ma, Wenliang Zhong, Gengchen Mai, Xiang Li, Tianming Liu, and Junzhou Huang. Chatgraph: interpretable text classification by converting chatgpt knowledge to graphs. arXiv preprint arXiv:2305.03513, 2023.">SMZ+23</a>]</span>.</p>
<p>First, reinstantiate everything that we need for this exercise:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span>!pip install langchain
!pip install openai
</pre></div>
</div>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;OPENAI_API_KEY&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">openai_api_key</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;key.txt&#39;</span><span class="p">,</span><span class="s1">&#39;r&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>

<span class="kn">from</span> <span class="nn">langchain.chat_models</span> <span class="kn">import</span> <span class="n">ChatOpenAI</span>

<span class="n">chat</span> <span class="o">=</span> <span class="n">ChatOpenAI</span><span class="p">(</span><span class="n">temperature</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
                  <span class="p">)</span>
</pre></div>
</div>
<p>We are going to extract information from Wikipedia, in the format of a knowledge graph.</p>
<p>A knowledge graph is a representation of information (knowledge), such as the following:</p>
<figure class="align-default" id="knowledgegraph">
<img alt="others/knowledgegraph.png" src="others/knowledgegraph.png" />
<figcaption>
<p><span class="caption-text">Figure: Knowledge Graph sample, from WWWC (2014) <span id="id4">[]</span></span><a class="headerlink" href="#knowledgegraph" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>It requires to identify, in a triplet format:</p>
<ul class="simple">
<li><p>the head entity</p></li>
<li><p>the relation</p></li>
<li><p>the tail entity</p></li>
</ul>
<p>You need to install the <code class="docutils literal notranslate"><span class="pre">wikipedia</span></code> library:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span>!pip install wikipedia
</pre></div>
</div>
<p>And you can retrieve information from Wikipedia:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">langchain.utilities</span> <span class="kn">import</span> <span class="n">WikipediaAPIWrapper</span>

<span class="n">wikipedia</span> <span class="o">=</span> <span class="n">WikipediaAPIWrapper</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">wikipedia</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="s1">&#39;Tesla, Inc.&#39;</span><span class="p">))</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>Page: Tesla, Inc.
Summary: Tesla, Inc. ( TESS-lə or  TEZ-lə) is an American multinational automotive and clean energy company headquartered in Austin, Texas. Tesla designs and manufactures electric vehicles (electric cars and trucks), battery energy storage from home to grid-scale, solar panels and solar roof tiles, and related products and services. Tesla is one of the world&#39;s most valuable companies and, as of 2023, is the world&#39;s most valuable automaker. In 2022, the company had the most worldwide sales of battery electric vehicles, capturing 18% of the market. Through its subsidiary Tesla Energy, the company develops and is a major installer of photovoltaic systems in the United States. Tesla Energy is also one of the largest global suppliers of battery energy storage systems, with 6.5 gigawatt-hours (GWh) installed in 2022.
Tesla was incorporated in July 2003 by Martin Eberhard and Marc Tarpenning as Tesla Motors. The company&#39;s name is a tribute to inventor and electrical engineer Nikola Tesla. In February 2004, via a $6.5 million investment, Elon Musk became the largest shareholder of the company. He has served as CEO since 2008. According to Musk, the purpose of Tesla is to help expedite the move to sustainable transport and energy, obtained through electric vehicles and solar power. Tesla began production of its first car model, the Roadster sports car, in 2008. This was followed by the Model S sedan in 2012, the Model X SUV in 2015, the Model 3 sedan in 2017, the Model Y crossover in 2020, and the Tesla Semi truck in 2022. The company plans production of the Cybertruck light-duty pickup truck in 2023. The Model 3 is the all-time bestselling plug-in electric car worldwide, and in June 2021 became the first electric car to sell 1 million units globally. Tesla&#39;s 2022 full year deliveries were around 1.31 million vehicles, a 40% increase over the previous year, and cumulative sales totaled 3 million cars as of August 2022. In October 2021, Tesla&#39;s market capitalization reached $1 trillion, the sixth company to do so in U.S. history.
Tesla has been the subject of several lawsuits, government scrutiny, journalistic criticism, and public controversies arising from statements and acts of CEO Elon Musk and from allegations of whistleblower retaliation, worker rights violations, and defects with their products.

Page: History of Tesla, Inc.
Summary: This is the corporate history of Tesla, Inc., an electric vehicle manufacturer and clean energy company founded in San Carlos, California in 2001 by American entrepreneurs Martin Eberhard and Marc Tarpenning. The company is named after Croatian-American inventor Nikola Tesla. Tesla is the world&#39;s leading electric vehicle manufacturer, and, as of the end of 2021, Tesla&#39;s cumulative global vehicle sales totaled 2.3 million units.



Page: Tesla Cybertruck
Summary: The Tesla Cybertruck is an upcoming battery electric light-duty truck announced by Tesla, Inc. in November 2019. Three models have been announced, with EPA range estimates of 400–800 kilometers (250–500 mi) and an estimated 0–100 km/h (0–62 mph) time of 2.9–6.5 seconds, depending on the model.The stated goal of Tesla in developing the Cybertruck is to provide a sustainable energy substitute for the roughly 6,500 fossil-fuel-powered trucks sold per day in the United States of America.The base price of the rear-wheel drive (RWD) model of the vehicle was announced to be US$39,900, with all-wheel drive (AWD) models starting at US$49,900. Production of the dual-motor AWD and tri-motor AWD Cybertruck were initially slated to begin in late 2021, with the RWD model release date in late 2022, but production dates were pushed back multiple times. As of July 2022, the start of limited production is estimated to start in mid-2023. As of January 2023, the start of mass production was estimated to be in 2024. However, as of February 2023, Elon Musk stated that the Cybertruck will be available later in 2023 with deliveries planned to begin
</pre></div>
</div>
<p>In this exercise, your task is to implement knowledge graph extraction following Shi et al. (2023) two stages process:</p>
<figure class="align-default" id="knowledgeextractor">
<img alt="others/knowledgeextractor.png" src="others/knowledgeextractor.png" />
<figcaption>
<p><span class="caption-text">Figure: Two Stage Knowledge Graph Extraction, from Shi et al. (2023)</span><a class="headerlink" href="#knowledgeextractor" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>The text refinement prompt to implement is the following:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>Please generate a refined document of the following document. And please ensure that the refined document meets the following criteria:
1. The refined document should be abstract and does not change any original meaning of the document.
2. The refined document should retain all the important objects, concepts, and relationships between them.
3. The refined document should only contain information that is from the document.
4. The refined document should be readable and easy to understand without any abbreviations and misspellings.
Here is the content: [x]
</pre></div>
</div>
<p>The knowledge extraction prompt to implement is:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>You are a knowledge graph extractor, and your task is to extract and return a knowledge graph from a given text.Let’s extract it step by step:
(1). Identify the entities in the text. An entity can be a noun or a noun phrase that refers to a real-world object or an abstract concept. You can use a named entity recognition (NER) tool or a part-of-speech (POS) tagger to identify the entities.
(2). Identify the relationships between the entities. A relationship can be a verb or a prepositional phrase that connects two entities. You can use dependency parsing
to identify the relationships.
(3). Summarize each entity and relation as short as possible and remove any stop words.
(4). Only return the knowledge graph in the triplet format: (’head entity’, ’relation’, ’tail entity’).
(5). Most importantly, if you cannot find any knowledge, please just output: &quot;None&quot;.
Here is the content: [x]
</pre></div>
</div>
<p>For example, the final output with Tesla is something as:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">(</span><span class="s1">&#39;Tesla, Inc.&#39;</span><span class="p">,</span> <span class="s1">&#39;is&#39;</span><span class="p">,</span> <span class="s1">&#39;a multinational automotive and clean energy company&#39;</span><span class="p">)</span>
<span class="p">(</span><span class="s1">&#39;Tesla, Inc.&#39;</span><span class="p">,</span> <span class="s1">&#39;designs and manufactures&#39;</span><span class="p">,</span> <span class="s1">&#39;electric vehicles, battery energy storage systems, solar panels, and related products and services&#39;</span><span class="p">)</span>
<span class="p">(</span><span class="s1">&#39;Tesla, Inc.&#39;</span><span class="p">,</span> <span class="s1">&#39;recognized as&#39;</span><span class="p">,</span> <span class="s2">&quot;one of the world&#39;s most valuable companies and the world&#39;s most valuable automaker as of 2023&quot;</span><span class="p">)</span>
<span class="p">(</span><span class="s1">&#39;Tesla, Inc.&#39;</span><span class="p">,</span> <span class="s1">&#39;captured&#39;</span><span class="p">,</span> <span class="s1">&#39;18</span><span class="si">% o</span><span class="s1">f the market for battery electric vehicles in 2022&#39;</span><span class="p">)</span>
<span class="p">(</span><span class="s1">&#39;Tesla, Inc.&#39;</span><span class="p">,</span> <span class="s1">&#39;is&#39;</span><span class="p">,</span> <span class="s1">&#39;a major installer of photovoltaic systems in the United States&#39;</span><span class="p">)</span>
<span class="p">(</span><span class="s1">&#39;Tesla Energy&#39;</span><span class="p">,</span> <span class="s1">&#39;is&#39;</span><span class="p">,</span> <span class="s1">&#39;one of the largest global suppliers of battery energy storage systems&#39;</span><span class="p">)</span>
<span class="p">(</span><span class="s1">&#39;Tesla Energy&#39;</span><span class="p">,</span> <span class="s1">&#39;installed&#39;</span><span class="p">,</span> <span class="s1">&#39;6.5 gigawatt-hours in 2022&#39;</span><span class="p">)</span>
<span class="p">(</span><span class="s1">&#39;Tesla&#39;</span><span class="p">,</span> <span class="s1">&#39;founded&#39;</span><span class="p">,</span> <span class="s1">&#39;in 2003 by Martin Eberhard and Marc Tarpenning as Tesla Motors&#39;</span><span class="p">)</span>
<span class="p">(</span><span class="s1">&#39;Elon Musk&#39;</span><span class="p">,</span> <span class="s1">&#39;became&#39;</span><span class="p">,</span> <span class="s1">&#39;the largest shareholder of the company in 2004&#39;</span><span class="p">)</span>
<span class="p">(</span><span class="s1">&#39;Elon Musk&#39;</span><span class="p">,</span> <span class="s1">&#39;has served as&#39;</span><span class="p">,</span> <span class="s1">&#39;CEO since 2008&#39;</span><span class="p">)</span>
<span class="p">(</span><span class="s1">&#39;Tesla&#39;</span><span class="p">,</span> <span class="s1">&#39;produced&#39;</span><span class="p">,</span> <span class="s1">&#39;several car models, including the Roadster sports car, Model S sedan, Model X SUV, Model 3 sedan, Model Y crossover, and Tesla Semi truck&#39;</span><span class="p">)</span>
<span class="p">(</span><span class="s1">&#39;Model 3&#39;</span><span class="p">,</span> <span class="s1">&#39;is&#39;</span><span class="p">,</span> <span class="s1">&#39;the all-time bestselling plug-in electric car worldwide and the first electric car to sell 1 million units globally&#39;</span><span class="p">)</span>
<span class="p">(</span><span class="s1">&#39;Tesla&#39;</span><span class="p">,</span> <span class="s1">&#39;2022 full year deliveries were&#39;</span><span class="p">,</span> <span class="s1">&#39;around 1.31 million vehicles, a 40</span><span class="si">% i</span><span class="s1">ncrease over the previous year&#39;</span><span class="p">)</span>
<span class="p">(</span><span class="s1">&#39;cumulative sales&#39;</span><span class="p">,</span> <span class="s1">&#39;totaled&#39;</span><span class="p">,</span> <span class="s1">&#39;3 million cars as of August 2022&#39;</span><span class="p">)</span>
<span class="p">(</span><span class="s1">&#39;Tesla&#39;</span><span class="p">,</span> <span class="s1">&#39;market capitalization reached&#39;</span><span class="p">,</span> <span class="s1">&#39;$1 trillion in October 2021&#39;</span><span class="p">)</span>
<span class="p">(</span><span class="s1">&#39;Tesla&#39;</span><span class="p">,</span> <span class="s1">&#39;faced&#39;</span><span class="p">,</span> <span class="s1">&#39;lawsuits, government scrutiny, journalistic criticism, and public controversies related to statements and acts of CEO Elon Musk, allegations of whistleblower retaliation, worker rights violations, and defects with their products&#39;</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>


                </article>
              

              
              
                <footer class="bd-footer-article">
                  <!-- Previous / next buttons -->
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#langchain">LangChain</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#first-prompts">First Prompts</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#multiple-questions">Multiple Questions</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#prompt-engineering-with-langchain">Prompt Engineering with LangChain</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#prompt-engineering">Prompt Engineering</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#prompt-templates">Prompt Templates</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction-to-templates">Introduction to Templates</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#output-parsers">Output Parsers</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#few-shot-prompt-learning">Few Shot Prompt Learning</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#memory">Memory</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#conversationchain">ConversationChain</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exercise">Exercise</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            <div class="bd-footer-content__inner">
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Thomas Lorans
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2022, Thomas Lorans.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div></div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=12da95d707ffb74b382d"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=12da95d707ffb74b382d"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>